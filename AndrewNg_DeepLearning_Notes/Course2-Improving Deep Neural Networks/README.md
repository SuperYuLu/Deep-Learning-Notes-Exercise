# Neural Networks and Deep Learn Notes   
## Source  
Coursera Andrew Ng class, "Deep Learning Specialization", Course2 "Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization", from deeplearning.ai  
## Table of Content  
- [WEEK1: Practical Aspect of Deep Learning](https://github.com/SuperYuLu/Deep-Learning-Notes-Exercise/blob/master/AndrewNg_DeepLearning_Notes/Course2-Improving%20Deep%20Neural%20Networks/Week1-Practical%20Aspect%20of%20Deep%20Learning.pdf)
  + Setting up ML aplication 
  + Regularizing deep neural network
  + Regularization: L2 norm, L1 norm
  + Droupout regularization
  + Data augmentation 
  + Normalizing Inputs 
  + Vanishing / exploding gradients
  + Weight random initialization 
  + Gradient checking

- [WEEK2: Optimization Algorithms](https://github.com/SuperYuLu/Deep-Learning-Notes-Exercise/blob/master/AndrewNg_DeepLearning_Notes/Course2-Improving%20Deep%20Neural%20Networks/Week2-Optimization%20Algorithms.pdf)
  + Mini-batch gradient descent
  + Expontially weighted averages & bias correction 
  + Gradient descent with momentum 
  + RMSprop
  + Adam Algorithm 
  + Learning rate decay
  + Problem of local optimal, plateaus
  
  
## Create  
20180324  
NOTABILITY Version 7.2 by &copy Ginger Labs, Inc.  

## Last update  
Jun. 23, 2018   


## Claim of rights  
All original lecture content copy rights belongs to Andrew Ng, the lecture notes and and summarization are based on the lecture contents and free to use and distribute according to GPL.
